{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "import string\n",
    "data = pd.read_pickle(\"darklyrics/lyrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.head()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert lyrics to lowercase\n",
    "data['lyrics'] = data.lyrics.apply(lambda x: [y.lower() for y in x])\n",
    "\n",
    "# Remove punctuation\n",
    "punctuation_regex = re.compile('[^0-9a-zA-Z ]+')\n",
    "data['lyrics'] = data.lyrics.apply(lambda x: [punctuation_regex.sub(\" \", y) for y in x])\n",
    "\n",
    "# Remove text between brackets\n",
    "brackets_regex = re.compile('\\[.*?\\]')\n",
    "data['lyrics'] = data.lyrics.apply(lambda x: [brackets_regex.sub(\"\", y) for y in x])\n",
    "\n",
    "# Remove double spaces\n",
    "double_space_regex = re.compile('\\s+')\n",
    "data['lyrics'] = data.lyrics.apply(lambda x: [double_space_regex.sub(\" \", y) for y in x])\n",
    "\n",
    "# Print cleaned lyrics\n",
    "data.iloc[0,2]\n",
    "data.iloc[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new column that places the lyrics a single string\n",
    "data['lyrics_string'] = data.lyrics.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove songs with no lyrics\n",
    "data = data[data.lyrics_string != \"\"]\n",
    "data.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code taken from http://h6o6.com/2012/12/detecting-language-with-python-and-the-natural-language-toolkit-nltk/\n",
    "# Used to detect the language on lyrics\n",
    "\n",
    "from nltk.corpus import stopwords   # stopwords to detect language\n",
    "from nltk import wordpunct_tokenize # function to split up our words\n",
    "from sys import stdin               # how else should we get our input :)\n",
    " \n",
    "def get_language_likelihood(input_text):\n",
    "    \"\"\"Return a dictionary of languages and their likelihood of being the \n",
    "    natural language of the input text\n",
    "    \"\"\"\n",
    " \n",
    "    input_text = input_text.lower()\n",
    "    input_words = wordpunct_tokenize(input_text)\n",
    " \n",
    "    language_likelihood = {}\n",
    "    total_matches = 0\n",
    "    for language in stopwords._fileids:\n",
    "        language_likelihood[language] = len(set(input_words) &\n",
    "                set(stopwords.words(language)))\n",
    " \n",
    "    return language_likelihood\n",
    " \n",
    "def get_language(input_text):\n",
    "    \"\"\"Return the most likely language of the given text\n",
    "    \"\"\"\n",
    " \n",
    "    likelihoods = get_language_likelihood(input_text)\n",
    "    return sorted(likelihoods, key=likelihoods.get, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove songs that are not in english\n",
    "data = data[data.apply(lambda x: get_language(x['lyrics_string']) == 'english', axis=1)]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove outlier years\n",
    "data = data[data.year > 1913]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General statistics\n",
    "len(data['artist'].unique()) # 7451 artists\n",
    "len(data['album'].unique()) # 22296 albums\n",
    "data['year'].max() # 2016\n",
    "data['year'].min() # 1968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save cleaned dataset in pickle file\n",
    "data.to_pickle(\"darklyrics/cleaned_lyrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"darklyrics/cleaned_lyrics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stem_text(text, stemmer):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "data['lyrics_string'] = data.lyrics_string.apply(lambda x: stem_text(x, stemmer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stem_text(text, stemmer):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "data['lyrics_string'] = data.lyrics_string.apply(lambda x: stem_text(x, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.iloc[0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group lyrics by artist\n",
    "artist_data = data.groupby('artist')['lyrics_string'].apply(lambda x: ' '.join(x))\n",
    "artist_data.head()\n",
    "artist_data.to_pickle(\"darklyrics/artist_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save cleaned dataset in pickle file\n",
    "data.to_pickle(\"darklyrics/clean_lyrics.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
